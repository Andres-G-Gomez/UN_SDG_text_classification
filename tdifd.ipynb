{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, \\\n",
    "                            accuracy_score, top_k_accuracy_score\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['doi', 'text_id', 'text', 'sdg', 'labels_negative', \n",
    "         'labels_positive', 'agreement']\n",
    "\n",
    "# laod data\n",
    "df = pd.read_csv('osdg.csv', error_bad_lines=False,\n",
    "                sep=\"\\t\", header= None, names=names)\n",
    "df = df.iloc[1:, :] \n",
    "df = df.drop(['doi', 'text_id', 'labels_negative', \n",
    "              'labels_positive'], axis = 1)\n",
    "\n",
    "priors = list(df.sdg.value_counts().values)\n",
    "\n",
    "# define discretization\n",
    "bins = [-1, 0.2, 0.4, 0.6, 0.8, 2]\n",
    "labels = np.linspace(1,10,5)\n",
    "\n",
    "# develop agreement variable\n",
    "df.agreement = df.agreement.astype(np.float16)\n",
    "df['cat_agreement'] = pd.cut(df.agreement, bins=bins, \n",
    "       labels = labels)\n",
    "\n",
    "X_train, X_subset, \\\n",
    "y_train, y_subset  = train_test_split(df[['text', 'agreement', 'cat_agreement']], df.sdg,\n",
    "                               test_size=0.3, random_state=0, \n",
    "                               stratify=df[['sdg', 'cat_agreement']])\n",
    "X_val, X_test, \\\n",
    "y_val, y_test  = train_test_split(X_subset, y_subset,\n",
    "                               test_size=0.5, random_state=0, \n",
    "                               stratify=pd.concat((X_subset, y_subset), axis = 1)[['sdg', 'cat_agreement']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, X_subset, y_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublinear_df = [True, False]\n",
    "min_df = [1, 2, 3, 4, 5]\n",
    "alphas = [1e-1, 1e-2, 1e-3, 0]\n",
    "cases = ['equal sample weights, no agreement', \n",
    "         'equal sample weights, agreement as feature',\n",
    "        'agreement as sample weights']\n",
    "labels = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iters = len(sublinear_df)*len(min_df)*len(alphas)*len(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5/120\n",
      "Iteration: 10/120\n",
      "Iteration: 15/120\n",
      "Iteration: 20/120\n",
      "Iteration: 25/120\n",
      "Iteration: 30/120\n",
      "Iteration: 35/120\n",
      "Iteration: 40/120\n",
      "Iteration: 45/120\n",
      "Iteration: 50/120\n",
      "Iteration: 55/120\n",
      "Iteration: 60/120\n",
      "Iteration: 65/120\n",
      "Iteration: 70/120\n",
      "Iteration: 75/120\n",
      "Iteration: 80/120\n",
      "Iteration: 85/120\n",
      "Iteration: 90/120\n",
      "Iteration: 95/120\n",
      "Iteration: 100/120\n",
      "Iteration: 105/120\n",
      "Iteration: 110/120\n",
      "Iteration: 115/120\n",
      "Iteration: 120/120\n",
      "Best validation accuracy: 0.7501037775010377        \n",
      "Top 3 accuracy %s 0.9113740141137402        \n",
      "Best parameters: {'alpha': 0.01, 'sublinear_df': False, 'min_df': 2, 'case': 'equal sample weights, agreement as feature'}\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "counter = 1\n",
    "for sublin_bool in sublinear_df:\n",
    "    for min_docs in min_df:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(sublinear_tf=sublin_bool, min_df=min_docs, max_features = 72400,\n",
    "                                stop_words='english', ngram_range=(1, 2), dtype = np.float32)\n",
    "        features = tfidf.fit_transform(list(X_train.text)).toarray()\n",
    "        \n",
    "        ##########\n",
    "        # 1. equal sample weights, no agreement as feature\n",
    "        # 2. equal sample weights, agreement as feature\n",
    "        # 3. agreement as sample weights, no agreement as feature\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            for case in cases:\n",
    "                \n",
    "                if case == cases[0]:\n",
    "                    ### training\n",
    "                    X_t = features\n",
    "                            \n",
    "                    clf = MultinomialNB(alpha = alpha, \n",
    "                                    fit_prior=True, \n",
    "                                    class_prior=priors).fit(X_t, y_train,\n",
    "                                                    sample_weight = None)\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    probs = clf.predict_proba(X_v)\n",
    "                    del X_v\n",
    "                    \n",
    "                elif case == cases[1]:\n",
    "                    ### training\n",
    "                    X_t = np.concatenate((features, X_train.agreement.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "                    clf = MultinomialNB(alpha = alpha, \n",
    "                                    fit_prior=True, \n",
    "                                    class_prior=priors).fit(X_t, y_train,\n",
    "                                                    sample_weight = None)\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    features_val = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    X_v = np.concatenate((features_val, X_val.agreement.values.reshape(-1,1)), axis=1)\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    probs = clf.predict_proba(X_v)\n",
    "                    del X_v\n",
    "                    \n",
    "                elif case == case[2]:\n",
    "                    ### training\n",
    "                    X_t = features\n",
    "                    sample_weights = X_train.agreement.values.reshape(-1,1)\n",
    "                            \n",
    "                    clf = MultinomialNB(alpha = alpha, \n",
    "                                    fit_prior=True, \n",
    "                                    class_prior=priors).it(X, Y,\n",
    "                                                    sample_weight = X_train.agreement.values.reshape(-1,1))\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    probs = clf.predict_proba(X_v)\n",
    "                    del X_v\n",
    "            \n",
    "                accuracy = accuracy_score(y_val, y_pred)\n",
    "                top_k = top_k_accuracy_score(y_val, probs, k=3)\n",
    "                \n",
    "                if counter%5 == 0:\n",
    "                    print(f'Iteration: {counter}/{total_iters}')\n",
    "                counter=counter+1\n",
    "                      \n",
    "                if accuracy > acc:\n",
    "                    acc = accuracy\n",
    "                    top_k_acc = top_k\n",
    "                    best_params = {'alpha': alpha, \n",
    "                                   'sublinear_df': sublin_bool, \n",
    "                                   'min_df': min_docs, 'case':case}\n",
    "                    \n",
    "print(f'Best validation accuracy: {acc}\\\n",
    "        \\nTop 3 accuracy %s {top_k_acc }\\\n",
    "        \\nBest parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf, features, clf, y_pred, accuracy, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vals = [0.01, 0.1, 1]\n",
    "total_iters = len(sublinear_df)*len(min_df)*len(C_vals)*len(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = list(y_train.value_counts().values)\n",
    "priors = {}\n",
    "for key in y_train.value_counts().index:\n",
    "    for value in test_values:\n",
    "        priors[key] = value\n",
    "        test_values.remove(value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5/90\n",
      "Iteration: 10/90\n",
      "Iteration: 15/90\n",
      "Iteration: 20/90\n",
      "Iteration: 25/90\n",
      "Iteration: 30/90\n",
      "Iteration: 35/90\n",
      "Iteration: 40/90\n",
      "Iteration: 45/90\n",
      "Iteration: 50/90\n",
      "Iteration: 55/90\n",
      "Iteration: 60/90\n",
      "Iteration: 65/90\n",
      "Iteration: 70/90\n",
      "Iteration: 75/90\n",
      "Iteration: 80/90\n",
      "Iteration: 85/90\n",
      "Iteration: 90/90\n",
      "Best validation accuracy: 0.79244499792445\n",
      " Best parameters: {'C': 1, 'sublinear_df': True, 'min_df': 2, 'case': 'equal sample weights, agreement as feature'}\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "counter = 1\n",
    "for sublin_bool in sublinear_df:\n",
    "    for min_docs in min_df:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(sublinear_tf=sublin_bool, min_df=min_docs, max_features = 72400,\n",
    "                                stop_words='english', ngram_range=(1, 2), dtype = np.float32)\n",
    "        features = tfidf.fit_transform(list(X_train.text)).toarray()\n",
    "        \n",
    "        ##########\n",
    "        # 1. equal sample weights, no agreement as feature\n",
    "        # 2. equal sample weights, agreement as feature\n",
    "        # 3. agreement as sample weights, no agreement as feature\n",
    "        \n",
    "        for C in C_vals:\n",
    "            for case in cases:\n",
    "                \n",
    "                if case == cases[0]:\n",
    "                    ### training\n",
    "                    X_t = features\n",
    "                    clf = LinearSVC(C=C, class_weight=priors).fit(X_t, y_train,\n",
    "                                                                         sample_weight = None)\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    del X_v\n",
    "                    \n",
    "                elif case == cases[1]:\n",
    "                    ### training\n",
    "                    X_t = np.concatenate((features, X_train.agreement.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "                    clf = LinearSVC(C=C, class_weight=priors).fit(X_t, y_train,\n",
    "                                                                         sample_weight = None)\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    features_val = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    X_v = np.concatenate((features_val, X_val.agreement.values.reshape(-1,1)), axis=1)\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    del X_v\n",
    "                    \n",
    "                elif case == case[2]:\n",
    "                    ### training\n",
    "                    X_t = features\n",
    "                    sample_weights = X_train.agreement.values.reshape(-1,1)\n",
    "                            \n",
    "                    clf = LinearSVC(C=C, class_weight=priors).fit(X_t, y_train,\n",
    "                                                                         sample_weight = X_train.agreement.values.reshape(-1,1))\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    del X_v\n",
    "                \n",
    "                accuracy = accuracy_score(y_val, y_pred)\n",
    "                \n",
    "                if counter%5 == 0:\n",
    "                    print(f'Iteration: {counter}/{total_iters}')\n",
    "                counter=counter+1\n",
    "                      \n",
    "                if accuracy > acc:\n",
    "                    acc = accuracy\n",
    "                    best_params = {'C': C, 'sublinear_df': sublin_bool, 'min_df': min_docs, 'case':case}\n",
    "                    \n",
    "print(f'Best validation accuracy: {acc}\\n Best parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf, features, clf, y_pred, accuracy, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5/36\n",
      "Iteration: 10/36\n",
      "Iteration: 15/36\n",
      "Iteration: 20/36\n",
      "Iteration: 25/36\n",
      "Iteration: 30/36\n",
      "Iteration: 35/36\n",
      "Iteration: 40/36\n",
      "Iteration: 45/36\n",
      "Iteration: 50/36\n",
      "Best validation accuracy: 0.7831050228310502        \n",
      "Top 3 accuracy %s 0.9315068493150684        \n",
      "Best parameters: {'C': 1, 'sublinear_df': False, 'min_df': 1, 'case': 'equal sample weights, agreement as feature'}\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "counter = 1\n",
    "for sublin_bool in sublinear_df:\n",
    "    for min_docs in min_df:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(sublinear_tf=sublin_bool, min_df=min_docs, max_features = 72400,\n",
    "                                stop_words='english', ngram_range=(1, 2), dtype = np.float32)\n",
    "        features = tfidf.fit_transform(list(X_train.text)).toarray()\n",
    "        \n",
    "        ##########\n",
    "        # 1. equal sample weights, no agreement as feature\n",
    "        # 2. equal sample weights, agreement as feature\n",
    "        # 3. agreement as sample weights, no agreement as feature\n",
    "        \n",
    "        for C in C_vals:\n",
    "            for case in cases:\n",
    "                \n",
    "                if case == cases[0]:\n",
    "                    ### training\n",
    "                    X_t = features\n",
    "                    clf = LogisticRegression(multi_class='ovr', solver='liblinear',\n",
    "                             C=C, class_weight = priors).fit(X_t, y_train,\n",
    "                                                                         sample_weight = None)\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    probs = clf.predict_proba(X_v)\n",
    "                    del X_v\n",
    "                    \n",
    "                elif case == cases[1]:\n",
    "                    ### training\n",
    "                    X_t = np.concatenate((features, X_train.agreement.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "                    clf = LogisticRegression(multi_class='ovr', solver='liblinear',\n",
    "                             C=C, class_weight = priors).fit(X_t, y_train,\n",
    "                                                                         sample_weight = None)\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    features_val = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    X_v = np.concatenate((features_val, X_val.agreement.values.reshape(-1,1)), axis=1)\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    probs = clf.predict_proba(X_v)\n",
    "                    del X_v\n",
    "                    \n",
    "                elif case == case[2]:\n",
    "                    ### training\n",
    "                    X_t = features\n",
    "                    sample_weights = X_train.agreement.values.reshape(-1,1)\n",
    "                            \n",
    "                    clf = LogisticRegression(multi_class='ovr', solver='liblinear',\n",
    "                             C=C, class_weight = priors).fit(X_t, y_train, sample_weight = X_train.agreement.values.reshape(-1,1))\n",
    "                    del X_t\n",
    "                    ### validation\n",
    "                    X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                    y_pred = clf.predict(X_v)\n",
    "                    probs = clf.predict_proba(X_v)\n",
    "                    del X_v\n",
    "                \n",
    "                accuracy = accuracy_score(y_val, y_pred)\n",
    "                top_k = top_k_accuracy_score(y_val, probs, k=3)\n",
    "                \n",
    "                if counter%5 == 0:\n",
    "                    print(f'Iteration: {counter}/{total_iters}')\n",
    "                counter=counter+1\n",
    "                      \n",
    "                if accuracy > acc:\n",
    "                    acc = accuracy\n",
    "                    top_k_acc = top_k\n",
    "                    best_params = {'C': C, 'sublinear_df': sublin_bool, 'min_df': min_docs, 'case':case}\n",
    "                    \n",
    "print(f'Best validation accuracy: {acc}\\\n",
    "        \\nTop 3 accuracy %s {top_k_acc }\\\n",
    "        \\nBest parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf, features, clf, y_pred, accuracy, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [100]\n",
    "max_depths = [300, 600]\n",
    "sublinear_df = [True, False]\n",
    "min_df = [1, 3, 5]\n",
    "\n",
    "total_iters = len(sublinear_df)*len(min_df)*len(trees)*len(cases)*len(max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = list(y_train.value_counts().values)\n",
    "priors = {}\n",
    "for key in y_train.value_counts().index:\n",
    "    for value in test_values:\n",
    "        priors[key] = value\n",
    "        test_values.remove(value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5/36\n",
      "Best accuracy:0.7141967621419676\n",
      "Iteration: 10/36\n",
      "Best accuracy:0.7141967621419676\n",
      "Iteration: 15/36\n",
      "Best accuracy:0.7185554171855542\n",
      "Iteration: 20/36\n",
      "Best accuracy:0.7185554171855542\n",
      "Iteration: 25/36\n",
      "Best accuracy:0.7185554171855542\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "counter = 1\n",
    "for sublin_bool in sublinear_df:\n",
    "    for min_docs in min_df:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(sublinear_tf=sublin_bool, min_df=min_docs, max_features = 72400,\n",
    "                                stop_words='english', ngram_range=(1, 2), dtype = np.float32)\n",
    "        features = tfidf.fit_transform(list(X_train.text)).toarray()\n",
    "        \n",
    "        ##########\n",
    "        # 1. equal sample weights, no agreement as feature\n",
    "        # 2. equal sample weights, agreement as feature\n",
    "        # 3. agreement as sample weights, no agreement as feature\n",
    "        \n",
    "        for n_estimators in trees:\n",
    "            for max_depth in max_depths:\n",
    "                for case in cases:\n",
    "\n",
    "                    if case == 'equal sample weights, no agreement':\n",
    "                        ### training\n",
    "                        X_t = features\n",
    "                        clf = RandomForestClassifier(n_estimators=n_estimators, random_state=0, max_depth = max_depth, class_weight = priors).fit(X_t, y_train,\n",
    "                                                                             sample_weight = None)\n",
    "                        del X_t\n",
    "                        ### validation\n",
    "                        X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                        y_pred = clf.predict(X_v)\n",
    "                        probs = clf.predict_proba(X_v)\n",
    "                        del X_v\n",
    "\n",
    "                    if case == 'equal sample weights, agreement as feature':\n",
    "                        ### training\n",
    "                        X_t = np.concatenate((features, X_train.agreement.values.reshape(-1,1)), axis=1)\n",
    "\n",
    "                        clf = RandomForestClassifier(n_estimators=n_estimators, random_state=0,  max_depth = max_depth, class_weight = priors).fit(X_t, y_train,\n",
    "                                                                             sample_weight = None)\n",
    "                        del X_t\n",
    "                        ### validation\n",
    "                        features_val = tfidf.transform(list(X_val.text)).toarray()\n",
    "                        X_v = np.concatenate((features_val, X_val.agreement.values.reshape(-1,1)), axis=1)\n",
    "                        y_pred = clf.predict(X_v)\n",
    "                        probs = clf.predict_proba(X_v)\n",
    "                        del X_v\n",
    "\n",
    "                    if case == 'agreement as sample weights':\n",
    "                        ### training\n",
    "                        X_t = features\n",
    "                        sample_weights = X_train.agreement.values.reshape(-1,1)\n",
    "\n",
    "                        clf = RandomForestClassifier(n_estimators=n_estimators, random_state=0,  max_depth = max_depth, class_weight = priors).fit(X_t, y_train,\n",
    "                                                                             sample_weight = X_train.agreement.values)\n",
    "                        del X_t\n",
    "                        ### validation\n",
    "                        X_v = tfidf.transform(list(X_val.text)).toarray()\n",
    "                        y_pred = clf.predict(X_v)\n",
    "                        probs = clf.predict_proba(X_v)\n",
    "                        del X_v\n",
    "\n",
    "                    accuracy = accuracy_score(y_val, y_pred)\n",
    "                    top_k = top_k_accuracy_score(y_val, probs, k=3)\n",
    "\n",
    "                    if accuracy > acc:\n",
    "                        acc = accuracy\n",
    "                        top_k_acc = top_k\n",
    "                        best_params = {'trees': n_estimators, 'sublinear_df': sublin_bool, \n",
    "                                       'min_df': min_docs, 'case':case, 'max depth': max_depth}\n",
    "\n",
    "                    if counter%5 == 0:\n",
    "                        print(f'Iteration: {counter}/{total_iters}\\nBest accuracy:{acc}')\n",
    "\n",
    "                    counter=counter+1\n",
    "                    \n",
    "print(f'Best validation accuracy: {acc}\\\n",
    "        \\nTop 3 accuracy %s {top_k_acc }\\\n",
    "        \\nBest parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.6.0",
   "language": "python",
   "name": "tensorflow-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
